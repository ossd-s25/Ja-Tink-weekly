---
layout: post
title: Week 8 - Open Source Presentations
---

## Open Source AI
While it is, of course, not officially a governing/regulatory organization, I think it is easy to perceive OSI (the Open Source Initiative) as something in that vein. Considering this, when Nick Vidal visited our class to discuss the new [Open Source AI Definiton](https://opensource.org/ai/open-source-ai-definition), I was expecting to hear about the ways that this definition would make AI more "responsible"- more fair, more transparentâ€” like regulations probably would. After hearing him speak, though, I came away with a different perspective on what this new definition does.

<!--more-->

## About the Definition - and what stood out to me as missing
Very broadly, the new Open Source AI definition says that AI models need to share the code that was used to generate them and detailed information on what data was used and where it came from. These requirements make a lot of sense to me- sharing source code is very "open source", and I understand that data is often sensitive and cannot always be shared directly. What I also expect from rules enforcing transparency and equity, though, is some kind of auditing information like fairness reports. The definition mentions nothing about this. I also worried that this definition gives companies no incentives to meet it halfway- that is, if a company wants to be "sort of open" and share their code, but they don't want to share their data information, shouldn't that be encouraged? Shouldn't we encourage as much transparency as possible? I realized, though, that I was misunderstanding the point of this definition, and really the whole point of open source in general.

## Nick's Response
When I asked Nick about these things, he told me that the definiton they came up with is the bare minimum for an AI project to follow the principles of open source. To add on more would be asking more than the definiton, and to take some off to give credit to partial attempts at the definition would missing the point entirely. There are no "degrees" of openness- it either is, or it isn't. Hearing this, I considered the principles of open source we talked about in the early weeks of class- and how it was all about *freedom* more than transparancy and fairness. Open source is not about moral judgements- indeed, a major criticism of open source is that it allows immoral actors to use open source projects without restriction! Admittedly, it would be unfair to say that open source does *nothing* to encourage moral and ethical software use- it is certainly true that the level of transparency that open source asks for encourages accountability, but really, "open source" does not exist to ensure purely benevolent software- it exists to support freedom and collaboration in the software space. I do think it is important to audit the fairness and morality of AI software and its usage, but after hearing from Nick, I am confident that the open source definition is not that place. The definition exists to cultivate freedom of the software, and I think it does a very good job at that.


